## 因子分析(factor analysis)

是指研究从变量群中提取共性因子的统计技术。 因子分析是简化、分析高维数据的一种统计方法。

因子分析又存在两个方向，一个是探索性因子分析（exploratory factor analysis）。另一个是验证性因子分析（confirmatory factor analysis）。

**探索性因子分析**是先不假定一堆自变量背后到底有几个因子以及关系，而是我们通过这个方法去寻找因子及关系。

**验证性因子分析**是假设一堆自变量背后有几个因子，试图验证这种假设是否正确。

因子分析有两个核心问题，一是如何构造因子变量，二是如何对因子变量进行命名解释。

## 因子分析的一般步骤

1. 将原始数据标准化处理 X
2. 计算相关矩阵C
3. 计算相关矩阵C的特征值 r 和特征向量 U
4. 确定公共因子个数k
5. 构造初始因子载荷矩阵,其中U为r的特征向量
6. 建立因子模型
7. 对初始因子载荷矩阵A进行旋转变换，旋转变换是使初始因子载荷矩阵结构简化，关系明确，使得因子变量更具有可解释性，如果初始因子不相关，可以用方差极大正交旋转，如果初始因子间相关，可以用斜交旋转，进过旋转后得到比较理想的新的因子载荷矩阵A'.
8. 将因子表示成变量的线性组合，其中的系数可以通过最小二乘法得到.
9. 计算因子得分.

## factor_analyzer模块进行因子分析

```
系统解释器：    pip install factor_analyzer；  
conda-jupyter：conda install -c desilinguist factor_analyzer；
```

算法核心：
对若干综合指标进行因子分析并提取公共因子,再以每个因子的方差贡献率作为权数与该因子的得分乘数之和构造得分函数。

In [ ]:

```
import pandas as pd
import numpy as np
from pandas import DataFrame,Series
from factor_analyzer import FactorAnalyzer
 
datafile = u'D:\\pythondata\\textdata.xlsx'
data = pd.read_excel(datafile)
data = data.fillna(0)#用0填充空值
 
fa = FactorAnalyzer()
fa.analyze(data, 5, rotation=None)#固定公共因子个数为5个
print("公因子方差:\n", fa.get_communalities())#公因子方差
print("\n成分矩阵:\n", fa.loadings)#成分矩阵
var = fa.get_factor_variance()#给出贡献率
print("\n解释的总方差（即贡献率）:\n", var)
 
fa_score = fa.get_scores(data)#因子得分
fa_score.head()
 
#将各因子乘上他们的贡献率除以总的贡献率,得到因子得分中间值
a = (fa.get_scores(data)*var.values[1])/var.values[-1][-1]
 
#将各因子得分中间值相加，得到综合得分
a['score'] = a.apply(lambda x: x.sum(), axis=1)
```

## 使用Python实现因子分析

### 0. 初始化构建数据

In [144]:

```
#导入库
import numpy as np
import pandas as pd
```

In [145]:

```
#构建数据集
data=pd.DataFrame(np.random.randint(50,100,size=(5, 10)))
data.columns=["特征1","特征2","特征3","特征4","特征5","特征6","特征7","特征8","特征9","特征10"]
data.index=['对象1','对象2','对象3','对象4','对象5']
```

In [146]:

```
#查看数据
data.head(3)
```

Out[146]:

|       | 特征1 | 特征2 | 特征3 | 特征4 | 特征5 | 特征6 | 特征7 | 特征8 | 特征9 | 特征10 |
| :---- | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | -----: |
| 对象1 |    62 |    89 |    52 |    63 |    84 |    51 |    67 |    62 |    59 |     56 |
| 对象2 |    50 |    98 |    82 |    85 |    61 |    97 |    63 |    96 |    88 |     59 |
| 对象3 |    52 |    54 |    63 |    94 |    93 |    62 |    88 |    75 |    60 |     61 |

### 1. 将原始数据标准化处理 X

In [147]:

```
data=(data-data.mean())/data.std() # 0均值规范化
```

In [148]:

```
data
```

Out[148]:

|       |    特征1 |     特征2 |     特征3 |     特征4 |     特征5 |     特征6 |     特征7 |     特征8 |     特征9 |    特征10 |
| :---- | -------: | --------: | --------: | --------: | --------: | --------: | --------: | --------: | --------: | --------: |
| 对象1 | -0.03371 |  0.688104 | -1.140585 | -1.661849 |  0.805243 | -1.042202 | -0.706947 | -1.092949 | -0.555162 | -1.161295 |
| 对象2 | -1.04501 |  1.179606 |  0.623206 | -0.187628 | -0.536829 |  1.651129 | -1.007775 |  1.200895 |  1.680906 | -0.633434 |
| 对象3 | -0.87646 | -1.223295 | -0.493861 |  0.415462 |  1.330402 | -0.398144 |  0.872402 | -0.215891 | -0.478056 | -0.281526 |
| 对象4 |  1.31469 |  0.141990 | -0.376275 |  0.683502 | -0.886935 | -0.163942 |  1.248438 |  0.863565 | -0.786479 |  0.950151 |
| 对象5 |  0.64049 | -0.786404 |  1.387515 |  0.750512 | -0.711882 | -0.046841 | -0.406118 | -0.755619 |  0.138790 |  1.126105 |

### 2. 计算相关矩阵C

In [149]:

```
C=data.corr() #相关系数矩阵
```

In [150]:

```
C
```

Out[150]:

|        |     特征1 |     特征2 |     特征3 |     特征4 |     特征5 |     特征6 |     特征7 |     特征8 |     特征9 |    特征10 |
| :----- | --------: | --------: | --------: | --------: | --------: | --------: | --------: | --------: | --------: | --------: |
| 特征1  |  1.000000 | -0.125185 |  0.053512 |  0.316812 | -0.563549 | -0.396722 |  0.423384 | -0.094383 | -0.565984 |  0.729563 |
| 特征2  | -0.125185 |  1.000000 | -0.147535 | -0.591560 | -0.318185 |  0.432786 | -0.561449 |  0.411365 |  0.491196 | -0.488141 |
| 特征3  |  0.053512 | -0.147535 |  1.000000 |  0.589383 | -0.641013 |  0.602759 | -0.321454 |  0.182064 |  0.601340 |  0.568450 |
| 特征4  |  0.316812 | -0.591560 |  0.589383 |  1.000000 | -0.456309 |  0.277390 |  0.568722 |  0.381112 | -0.006200 |  0.856592 |
| 特征5  | -0.563549 | -0.318185 | -0.641013 | -0.456309 |  1.000000 | -0.519135 |  0.078552 | -0.510000 | -0.346663 | -0.653499 |
| 特征6  | -0.396722 |  0.432786 |  0.602759 |  0.277390 | -0.519135 |  1.000000 | -0.365044 |  0.775420 |  0.916689 |  0.016999 |
| 特征7  |  0.423384 | -0.561449 | -0.321454 |  0.568722 |  0.078552 | -0.365044 |  1.000000 |  0.189765 | -0.689200 |  0.485650 |
| 特征8  | -0.094383 |  0.411365 |  0.182064 |  0.381112 | -0.510000 |  0.775420 |  0.189765 |  1.000000 |  0.486129 |  0.134735 |
| 特征9  | -0.565984 |  0.491196 |  0.601340 | -0.006200 | -0.346663 |  0.916689 | -0.689200 |  0.486129 |  1.000000 | -0.219108 |
| 特征10 |  0.729563 | -0.488141 |  0.568450 |  0.856592 | -0.653499 |  0.016999 |  0.485650 |  0.134735 | -0.219108 |  1.000000 |

### 3. 计算相关矩阵C的特征值 r 和特征向量 U

In [151]:

```
import numpy.linalg as nlg #导入nlg函数，linalg=linear+algebra

eig_value,eig_vector=nlg.eig(C) #计算特征值和特征向量

eig=pd.DataFrame() #利用变量名和特征值建立一个数据框

eig['names']=data.columns#列名

eig['eig_value']=eig_value#特征值
```

In [152]:

```
eig
```

Out[152]:

|      |  names |                                         eig_value |
| :--- | -----: | ------------------------------------------------: |
| 0    |  特征1 |                           (3.6178767303359534+0j) |
| 1    |  特征2 |                           (3.7848055707590635+0j) |
| 2    |  特征3 |                           (1.3573249428605407+0j) |
| 3    |  特征4 |                           (1.2399927560444444+0j) |
| 4    |  特征5 |  (2.1503169629143618e-16+1.1037482747695011e-16j) |
| 5    |  特征6 |  (2.1503169629143618e-16-1.1037482747695011e-16j) |
| 6    |  特征7 |                        (4.238056948937482e-17+0j) |
| 7    |  特征8 | (-2.7064622349968394e-16+2.5829577785548796e-17j) |
| 8    |  特征9 | (-2.7064622349968394e-16-2.5829577785548796e-17j) |
| 9    | 特征10 |                      (-1.6282653497481437e-16+0j) |

### 4. 确定公共因子个数k

In [153]:

```
from math import sqrt

for k in range(1,11): #确定公共因子个数
    if eig['eig_value'][:k].sum()/eig['eig_value'].sum()>=0.8: #如果解释度达到80%, 结束循环
        print(k)
        break
3
```

In [155]:

```
eig['eig_value'][:3].sum()/eig['eig_value'].sum()
```

Out[155]:

```
(0.8760007243955555+0j)
```

### 5. 构造初始因子载荷矩阵A

In [156]:

```
col0=list(sqrt(eig_value[0])*eig_vector[:,0]) #因子载荷矩阵第1列
col1=list(sqrt(eig_value[1])*eig_vector[:,1]) #因子载荷矩阵第2列
col2=list(sqrt(eig_value[2])*eig_vector[:,2]) #因子载荷矩阵第3列
A=pd.DataFrame([col0,col1,col2]).T #构造因子载荷矩阵A
A.columns=['factor1','factor2','factor3'] #因子载荷矩阵A的公共因子
/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: ComplexWarning: Casting complex values to real discards the imaginary part
  """Entry point for launching an IPython kernel.
/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: ComplexWarning: Casting complex values to real discards the imaginary part
  
/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: ComplexWarning: Casting complex values to real discards the imaginary part
  This is separate from the ipykernel package so we can avoid doing imports until
```

In [157]:

```
A
```

Out[157]:

|      |                   factor1 |                   factor2 |                   factor3 |
| :--- | ------------------------: | ------------------------: | ------------------------: |
| 0    |   (0.7258972871759931+0j) |    (0.195764810516731+0j) |   (0.6134162515864857+0j) |
| 1    |     (-0.5879677931131+0j) | (-0.45462634230687354+0j) |   (0.6651556380337422+0j) |
| 2    |     (0.39128490248412+0j) |  (-0.7286311172822467+0j) | (-0.32426890310714734+0j) |
| 3    |   (0.8700578532724493+0j) | (-0.30144478238954536+0j) |  (-0.3458116643591109+0j) |
| 4    |  (-0.5069962398429965+0j) |   (0.6991573435745143+0j) | (-0.46872779482399285+0j) |
| 5    | (-0.10911519738585919+0j) |  (-0.9628827963582759+0j) | (-0.12683028873166624+0j) |
| 6    |   (0.6756467356889502+0j) |  (0.43522130228334177+0j) | (-0.01372604304275851+0j) |
| 7    |  (0.12912127991906552+0j) |  (-0.6937402312061534+0j) |  (0.18441987041279836+0j) |
| 8    | (-0.38573863856153534+0j) |  (-0.8962626145844621+0j) | (-0.20757371535363026+0j) |
| 9    |   (0.9717112549236306+0j) | (-0.16757177998509953+0j) | (0.028280482071635905+0j) |

### 6. 建立因子模型

In [158]:

```
h=np.zeros(10) #变量共同度，反映变量对共同因子的依赖程度，越接近1，说明公共因子解释程度越高，因子分析效果越好

D=np.mat(np.eye(10))#特殊因子方差，因子的方差贡献度 ，反映公共因子对变量的贡献，衡量公共因子的相对重要性

A=np.mat(A) #将因子载荷阵A矩阵化
```

In [159]:

```
for i in range(10):
    a=A[i,:]*A[i,:].T #A的元的行平方和
    h[i]=a[0,0]  #计算变量X共同度,描述全部公共因子F对变量X_i的总方差所做的贡献，及变量X_i方差中能够被全体因子解释的部分
    D[i,i]=1-a[0,0] #因为自变量矩阵已经标准化后的方差为1，即Var(X_i)=第i个共同度h_i + 第i个特殊因子方差
/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: ComplexWarning: Casting complex values to real discards the imaginary part
  This is separate from the ipykernel package so we can avoid doing imports until
/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: ComplexWarning: Casting complex values to real discards the imaginary part
  after removing the cwd from sys.path.
```

### 7. 对初始因子载荷矩阵A进行旋转变换.

### 8. 将因子表示成变量的线性组合.

In [160]:

```
from numpy import eye, asarray, dot, sum, diag #导入eye,asarray,dot,sum,diag 函数
from numpy.linalg import svd #导入奇异值分解函数

def varimax(Phi, gamma = 1.0, q =10, tol = 1e-6): #定义方差最大旋转函数
    p,k = Phi.shape #给出矩阵Phi的总行数，总列数
    R = eye(k) #给定一个k*k的单位矩阵
    d=0
    for i in range(q):
        d_old = d
        Lambda = dot(Phi, R)#矩阵乘法

        u,s,vh = svd(dot(Phi.T,asarray(Lambda)**3 - (gamma/p) * dot(Lambda, diag(diag(dot(Lambda.T,Lambda)))))) #奇异值分解svd

        R = dot(u,vh)#构造正交矩阵R

        d = sum(s)#奇异值求和

    if d_old!=0 and d/d_old:
        return dot(Phi, R)#返回旋转矩阵Phi*R

rotation_mat=varimax(A)#调用方差最大旋转函数
rotation_mat=pd.DataFrame(rotation_mat)#数据框化
```

In [161]:

```
rotation_mat
```

Out[161]:

|      |                         0 |                         1 |                         2 |
| :--- | ------------------------: | ------------------------: | ------------------------: |
| 0    |  (0.21323966276777256+0j) |  (0.49435123401088754+0j) |   (0.8072644758263128+0j) |
| 1    |   (-0.861602627623943+0j) |  (-0.3811032744161447+0j) |    (0.327451471162522+0j) |
| 2    |   (0.5187267141393943+0j) |  (-0.6888237247452673+0j) |  (0.21354618650891108+0j) |
| 3    |   (0.9090551329962969+0j) |    (-0.19106991871067+0j) |   (0.3233672577963704+0j) |
| 4    | (-0.13785145883578895+0j) |   (0.4329888308401448+0j) |  (-0.8712574657322602+0j) |
| 5    |  (0.00308412468592269+0j) |  (-0.9638776743736194+0j) |   (0.1614485830909371+0j) |
| 6    |   (0.5434813068461372+0j) |   (0.5485709862761546+0j) |  (0.22316460245920597+0j) |
| 7    | (0.004286980412996384+0j) |  (-0.5800754028893825+0j) |  (0.44210027220828235+0j) |
| 8    |   (-0.171684278987763+0j) |  (-0.9797037284493241+0j) | (-0.07663505527980378+0j) |
| 9    |   (0.7652785107076661+0j) | (0.052660107008933976+0j) |   (0.6202246078943493+0j) |

### 9. 计算因子得分.

In [162]:

```
data=np.mat(data) #矩阵化处理

factor_score=(data).dot(A) #计算因子得分

factor_score=pd.DataFrame(factor_score)#数据框化

factor_score.columns=['因子A','因子B','因子C'] #对因子变量进行命名
factor_score
#factor_score.to_excel(outputfile)#打印输出因子得分矩阵
```

Out[162]:

|      |                    因子A |                    因子B |                     因子C |
| :--- | -----------------------: | -----------------------: | ------------------------: |
| 0    |  (-4.148852018585423+0j) |  (3.7218173860420958+0j) |   (1.0268404260474102+0j) |
| 1    | (-3.0692735299739105+0j) |  (-5.775657145949657+0j) | (-0.08291739333905472+0j) |
| 2    | (0.09261106423291608+0j) |   (2.937792806185489+0j) |  (-1.8684628565463521+0j) |
| 3    |   (3.967516384935492+0j) | (0.28862584652034023+0j) |    (1.555317728379365+0j) |
| 4    |   (3.157998099390924+0j) | (-1.1725788927982674+0j) |  (-0.6307779045413688+0j) |